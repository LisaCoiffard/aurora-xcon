name: pga_me_baseline
defaults: 
  - hydra: default # load default hydra settings
  - wandb: default # load default wandb settings
  - env: kheperax # load environment settings
  - _self_

seed: 42
backend: jax

# QD settings
batch_size: 512
num_iterations: 2000
num_total_steps:

metrics_log_period: 5
me_repertoire: true

# Emitter settings
iso_sigma: 0.005
line_sigma: 0.05
proportion_mutation_ga: 0.5

num_critic_training_steps: 3000
num_pg_training_steps: 150 

# TD3 params
replay_buffer_size: 1_000_000 
critic_hidden_layer_size: [256, 256]
critic_learning_rate: 3e-4 
greedy_learning_rate: 3e-4 
policy_learning_rate: 5e-3 
noise_clip: 0.5 
policy_noise: 0.2 
discount: 0.99 
reward_scaling: 1.0 
transitions_batch_size: 100 
soft_tau_update: 0.005 
policy_delay: 2 

# Extinction settings
extinction: false
extinction_freq: 10
remaining_prop: 0.05

env_params:
  kheperax:
    iso_sigma: 0.2
    line_sigma: 0
  ant_maze:
    iso_sigma: 0.005
    line_sigma: 0.05
  walker:
    iso_sigma: 0.005
    line_sigma: 0.05
  half_cheetah:
    iso_sigma: 0.005
    line_sigma: 0.05

wandb: 
  group: ${env.name}
  tags: ['${name}', '${env.name}']